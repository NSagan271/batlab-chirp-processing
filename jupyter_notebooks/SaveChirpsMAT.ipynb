{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c06498f-9a48-4561-9c79-a5476658d82c",
   "metadata": {},
   "source": [
    "# Save Different Stages of the Chirp Sequence Pipeline as MAT Files\n",
    "\n",
    "If you haven't gone through the `Walkthrough.ipynb` notebook, please take a look at that notebook first, as it contains descriptions of all configurable parameters used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f8c79d-38ea-4552-92b3-f47f27d82e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg;\n",
    "Pkg.develop(path=\"../BatlabJuliaUtils\")\n",
    "using BatlabJuliaUtils\n",
    "using Plots;\n",
    "using Printf;\n",
    "using MAT;\n",
    "using Statistics;\n",
    "using DataStructures;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c58ac-8ecf-401a-811a-6679f38a22ae",
   "metadata": {},
   "source": [
    "## Specify MAT Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c05d58-2ab4-46a6-bfd4-9d05db2249b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILENAME = \"../data/Pu166_02.mat\";\n",
    "CENTROID_FILENAME = \"../data/centroid/Pu166_002_centroidxyz.mat\";\n",
    "MIC_POSITION_FILENAME = \"../data/mic_positions_fall2021.mat\";\n",
    "\n",
    "CENTROID_VARIABLE_NAME = collect(keys(matread(CENTROID_FILENAME)))[1];\n",
    "MIC_POSITION_VARIABLE_NAME = collect(keys(matread(MIC_POSITION_FILENAME)))[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f472c0e3-00e1-42e0-a946-c403e0e5a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(@printf \"Do the variable names for these MAT files look right?\\n\\tFor the centroid file: \\\"%s\\\",\\n\\tand for the mic position file: \\\"%s\\\"\" CENTROID_VARIABLE_NAME MIC_POSITION_VARIABLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b357dc6-7580-490e-a70a-d2239b56dab6",
   "metadata": {},
   "source": [
    "If the variable names for the MAT files don't look right, then uncomment and run the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b79167-9d5b-4b3b-83f7-5fe465a2bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# println(\"The keys of the centroid file are:\\n\", keys(matread(CENTROID_FILENAME)), \"\\nand the MAT file looks like\")\n",
    "# centroids = matread(CENTROID_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d65a45-70fe-4c50-baa2-9cbe8ca50629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# println(\"The keys of the mic position file are:\\n\", keys(matread(MIC_POSITION_FILENAME)), \"\\nand the MAT file looks like\")\n",
    "# mic_locations = matread(MIC_POSITION_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3de93a-838d-49fb-84b2-63f173591b29",
   "metadata": {},
   "source": [
    "## Set up where to save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a0aa60-e32b-4bbb-91ab-3666dde8e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Makes a new folder in the current directory to store the data\n",
    "mkpath(\"saved_chirp_sequences\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b945b-9df6-4c90-b356-3cc5eef77316",
   "metadata": {},
   "source": [
    "Each function that saves data takes in the arguments `dataset_name` and `save_dir`, among others like the microphone and centroid data, _etc._\n",
    "- `dataset_name` is the name of the dataset, e.g. `Pu166_01`. The name of any MAT file saved by this notebook will start with this dataset name.\n",
    "- `save_dir` is the directory in which to save the data. A default directory was created in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5c19a-d096-4949-a276-f69e29435277",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"Pu166_02\";\n",
    "SAVE_DIR = \"./saved_chirp_sequences\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4575e-25e4-4cc6-b31a-dcabbd36b4a0",
   "metadata": {},
   "source": [
    "## Read in microphone and centroid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2561cc8-cbe6-4e2c-a05c-768e0a174ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in microphone data\n",
    "y = readmicdata(AUDIO_FILENAME);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c3f3f-44d0-42c2-9df1-4a0a1739f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = Matrix(transpose( matread(CENTROID_FILENAME)[CENTROID_VARIABLE_NAME]));\n",
    "mic_positions = Matrix(transpose( matread(MIC_POSITION_FILENAME)[MIC_POSITION_VARIABLE_NAME]));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf2cee-9c8e-4caa-bc01-f3ef4f147f00",
   "metadata": {},
   "source": [
    "## Stage 1: High-SNR Regions\n",
    "**Note**: to run future sections, you need to run the **Parameters** and **Load Helper Functions** parts of previous sections, but you don't need to run the **Save Data** part of Stage 1 if you only want the output from Stage 2, _e.g._. Please do read through the description of the saved data for all stages, however, so that you can understand what is saved for each stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb58af-1093-49f6-8b66-4a891117dc1b",
   "metadata": {},
   "source": [
    "### Parameters (From `Walkthrough.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81bf25a-e7c3-4631-8eeb-d071b43a9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET THESE PARAMETERS ###\n",
    "SIGNAL_THRESH = 30\n",
    "MAXFILTER_LENGTH_MS = 0.1\n",
    "MAXFILTER_LENGTH = Int64(round(MAXFILTER_LENGTH_MS / 1000 * FS));\n",
    "\n",
    "MIN_PEAK_THRESH = 35;\n",
    "SNR_DROP_THRESH = 20;\n",
    "PEAK_SNR_THRESH_RADIUS = 2500;\n",
    "\n",
    "TAIL_SNR_THRESH = 20;\n",
    "TAIL_MAXFILTER_LENGTH = 50;\n",
    "#############################\n",
    "HIGH_SNR_PARAMS = Dict(\n",
    "    :signal_thresh => SIGNAL_THRESH,\n",
    "    :maxfilter_length => MAXFILTER_LENGTH,\n",
    "    :min_peak_thresh => MIN_PEAK_THRESH,\n",
    "    :snr_drop_thresh => SNR_DROP_THRESH,\n",
    "    :peak_snr_thresh_radius => PEAK_SNR_THRESH_RADIUS,\n",
    "    :tail_snr_thresh => TAIL_SNR_THRESH,\n",
    "    :tail_maxfilter_length => TAIL_MAXFILTER_LENGTH\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bfc4a1-e2a2-4591-8b49-d6f475321f49",
   "metadata": {},
   "source": [
    "### Load Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfebc398-9bfa-40a6-8b5f-88d4bea3f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"SaveHighSnrRegions.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f09abd-9da0-4a49-b579-ad2caa19ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function getmicfield(mat_data, name_after_mic_k_, mic)\n",
    "    return mat_data[\"mic_\" * string(mic) * \"_\" * name_after_mic_k_];\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05409ab5-a213-48b1-a64c-09d0794d049f",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed07927-6675-4131-96f9-f0ce008da469",
   "metadata": {},
   "outputs": [],
   "source": [
    "savehighsnrregions(y, DATASET_NAME, SAVE_DIR);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d2d138-e118-4217-bfee-84ef8b3bce19",
   "metadata": {},
   "source": [
    "### Breakdown of saved data\n",
    "A mat file will be stored in `save_dir` from above, with the name format `{dataset_name}_high_snr_regions.mat` (for example. `Pu166_01_high_snr_regions.mat`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea291f-433f-43c0-8235-94f99bc7a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_stage1 = (@sprintf \"%s/%s_high_snr_regions.mat\" SAVE_DIR DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3325911-d0e1-43af-8c61-e7e8e386762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_mat_data_stage1 = matreadsorted(filename_stage1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62efe03b-8e0b-415f-bb98-ee23b413b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "mics = Vector{Int}(undef, 0);\n",
    "num_high_snr_regions_per_mic = Dict();\n",
    "for key=keys(saved_mat_data_stage1)\n",
    "    maybe_match = match(r\"mic_(\\d)_high_snr_region_onsets_ms\", key);\n",
    "    if isnothing(maybe_match)\n",
    "        continue\n",
    "    end\n",
    "    mic = parse(Int64, maybe_match[1]);\n",
    "    mics = vcat(mics, mic);\n",
    "    num_high_snr_regions_per_mic[mic] = length(saved_mat_data_stage1[key]);\n",
    "    @printf \"***For mic %d, there were %d high-SNR regions found.***\\n\" mic length(saved_mat_data_stage1[key])\n",
    "end\n",
    "println(\"Mics that found high-SNR regions: \", mics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b9e093-dbf0-4eb5-994c-7efce73a98e7",
   "metadata": {},
   "source": [
    "**The variables in the mat file are**:\n",
    "- `mic_k_data_per_high_snr_region`: array where each column is a different high-\n",
    "    SNR region for microphone `k`. Zeros are added to the end of each column to make all columns\n",
    "    the same length.\n",
    "- `mic_k_high_snr_region_lengths`: length, in audio samples, of each high-SNR region.\n",
    "- `mic_k_high_snr_region_onsets_ms`: time, in milliseconds since the beginning of\n",
    "    the microphone data, that the high-SNR region starts.\n",
    "- `mic_k_snr_data_per_high_snr_region`: SNR of each high-SNR region, in the same\n",
    "    format as `mic_k_data_per_high_snr_region`.\n",
    "\n",
    "`k` is the number of any microphone that found at least one high-SNR region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a77e131-b4d4-40dc-a327-ec9d1d016c55",
   "metadata": {},
   "source": [
    "**We can get the mic data for the `i`-th high-SNR region for microphone `k` as follows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0d896-e82a-4f89-8a28-b2e4a43c4f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1; # SET TO THE MIC YOU WANT\n",
    "i = 10; # SET TO WHICH HIGH-SNR REGION YOU WANT\n",
    "\n",
    "@assert !isnothing(findfirst(mics .== k)) \"Mic chosen didn't find any high-SNR regions!\"\n",
    "@assert i <=  num_high_snr_regions_per_mic[k] \"k is larger than the number of high-SNR regions found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffe32a-a621-4f9c-9ff7-0d729832e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_snr_region_length = getmicfield(saved_mat_data_stage1, \"high_snr_region_lengths\", k)[i];\n",
    "mic_data = getmicfield(saved_mat_data_stage1, \"data_per_high_snr_region\", k);\n",
    "\n",
    "## Remove extra zeros at the end!\n",
    "mic_data = mic_data[1:high_snr_region_length, i]\n",
    "plotSTFTtime(mic_data, noverlap=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7685e5-4390-4bf5-b91e-a76787ac2e70",
   "metadata": {},
   "source": [
    "## Stage 2: Chirp Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eec874-8670-4274-b348-8b60ec7419b6",
   "metadata": {},
   "source": [
    "### Parameters (From `Walkthrough.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec597774-e89a-4221-b48d-0becfc08e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET THESE PARAMETERS ###\n",
    "TEMPORAL_TOLERANCE_MS = 2;\n",
    "SINGLE_MIC_SNR_THRESH = 85; \n",
    "ANY_MIC_SNR_THRESH = 45; \n",
    "#############################\n",
    "CHIRP_SEQ_PARAMS = Dict(\n",
    "    :vocalization_start_tolerance_ms => TEMPORAL_TOLERANCE_MS,\n",
    "    :single_mic_snr_thresh => SINGLE_MIC_SNR_THRESH,\n",
    "    :any_mic_snr_thresh => ANY_MIC_SNR_THRESH,\n",
    "    HIGH_SNR_PARAMS...\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465da29-600b-4b2c-bbea-b08542cd3d76",
   "metadata": {},
   "source": [
    "### Load Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6d9a0-70b9-45f8-8601-7f9a779a8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"SaveChirpSequences.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b9155-b017-4cb1-9013-ce646340b488",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd10d3-c823-4996-90bc-57cecaad5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "savechirpsequences(y, centroids, mic_positions, DATASET_NAME, SAVE_DIR; CHIRP_SEQ_PARAMS...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0d39b-7509-4700-a949-096880e3b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_stage2 = (@sprintf \"%s/%s_chirp_sequences.mat\" SAVE_DIR DATASET_NAME)\n",
    "saved_mat_data_stage2 = matreadsorted(filename_stage2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99964da-89fa-4156-aa0f-ac7e826e9c4f",
   "metadata": {},
   "source": [
    "### Breakdown of saved data\n",
    "\n",
    "**`vocalization_times`**: list of estimated times that the bat vocalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32addf-412f-4a6f-88ec-b33576a91d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocalization_times = saved_mat_data_stage2[\"vocalization_times\"];\n",
    "println(\"There were \", length(vocalization_times), \" vocalizations!\");\n",
    "myplot(vocalization_times, ones(length(vocalization_times)), line=:stem, marker=:circle, color=:1, markersize=5,\n",
    "    title=\"Vocalizations \", xlabel=\"Milliseconds\", ylabel=\"\", size=(1200, 200), yrange=(0, 1.2), legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a41b7e5-c34d-43ce-a006-e978a0fea5d4",
   "metadata": {},
   "source": [
    "**`valid_mics`**: matrix with N columns and 4 rows, where N is the total number of chirp sequences. Each column consists of 0s and 1s for whether each microphone heard anything for the chirp sequence corresponding to that column.\n",
    "\n",
    "For instance, if `valid_mics` is\n",
    "```\n",
    "1   1   0   1   1\n",
    "0   0   0   0   0\n",
    "1   0   1   1   1\n",
    "0   1   1   0   0\n",
    "```\n",
    "this means that the first vocalization was picked up by microphones 1 and 3, the second vocalization was picked up by microphones 1 and 4, the third was picked up by microphones 3 and 4, _etc._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9563081-c216-4454-9fe4-1c8b083730f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mics_stage2 = saved_mat_data_stage2[\"valid_mics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1126a88b-f5f8-4031-ab11-83dccf7eec73",
   "metadata": {},
   "source": [
    "**Rest of the variables:**\n",
    "- `mic_k_chirp_seq_lengths`: length, in samples, of the single-mic chirp sequence heard by microphone `k` for each vocalization. This will be `0` for vocalizations that mic `k` did not pick up.\n",
    "- `mic_k_data_per_chirp_seq`: oscillogram data for the single-mic chirp sequence heard by microphone `k` for each vocalization. Zeros are added to the end of each column to make all columns the same length. This is all zeros for vocalizations that mic `k` did not pick up.\n",
    "- `mic_k_snr_data_per_chirp_seq`: same as `mic_k_data_per_chirp_seq`, but SNR data instead of oscillogram data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ddf81-a04b-4572-ad25-69e241c44a54",
   "metadata": {},
   "source": [
    "**Get microphone data for a vocalization**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff88456-bd1d-4425-a108-152100b512a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIC = 1; ## Change this to any: 1, 2, 3, or 4 ##\n",
    "CHIRP_NUM = 1; # You can change this too\n",
    "if valid_mics_stage2[MIC, CHIRP_NUM] == 0\n",
    "    println(\"Mic \", MIC, \" did not hear vocalization \", CHIRP_NUM, \".\");\n",
    "else\n",
    "    seq_length = getmicfield(saved_mat_data_stage2, \"chirp_seq_lengths\", MIC)[CHIRP_NUM];\n",
    "    data = getmicfield(saved_mat_data_stage2, \"data_per_chirp_seq\", MIC)[1:seq_length, CHIRP_NUM];\n",
    "    plotSTFTtime(data, noverlap=255)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7d713a-b18f-4c85-8169-21c6ad8dea77",
   "metadata": {},
   "source": [
    "## Stage 3: Chirps and Melodies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c65124-f25f-46ff-a399-b17e19ba884a",
   "metadata": {},
   "source": [
    "### Parameters (From `Walkthrough.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f767d3-1e8b-4588-8477-3f7379c415ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET THESE PARAMETERS ###\n",
    "MAXIMUM_MELODY_SLOPE = 5;\n",
    "MELODY_DROP_THRESH_DB = 20;\n",
    "FIND_HIGHEST_SNR_IN_FIRST_MS = 1.5;\n",
    "MELODY_THRESH_DB_LOW = -20;\n",
    "MOVING_AVG_SIZE = 10;\n",
    "MELODY_DROP_THRESH_DB_START = 35; \n",
    "#############################\n",
    "CHIRP_MELODY_PARAMS = Dict(\n",
    "    :maximum_melody_slope => MAXIMUM_MELODY_SLOPE,\n",
    "    :melody_drop_thresh_db => MELODY_DROP_THRESH_DB,\n",
    "    :melody_thresh_db_low => MELODY_THRESH_DB_LOW,\n",
    "    :moving_avg_size => MOVING_AVG_SIZE,\n",
    "    :melody_drop_thresh_db_start => MELODY_DROP_THRESH_DB_START,\n",
    "    :find_highest_snr_in_first_ms => FIND_HIGHEST_SNR_IN_FIRST_MS,\n",
    "    CHIRP_SEQ_PARAMS...\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3f624-4fd9-4d8e-8faf-dd79c954553a",
   "metadata": {},
   "source": [
    "### Load Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bf3e46-8ad4-43c3-9038-7b226defad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"SaveChirpsAndMelodies.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024cf322-7333-4cd0-8aa9-f3ea228f2851",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44660637-0c77-45ee-ba65-46a9a1648e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "savechirpsandmelodies(y, centroids, mic_positions, DATASET_NAME, SAVE_DIR; CHIRP_MELODY_PARAMS...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5ca9d-88c6-48d9-9f31-05b4476ccfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_stage3 = (@sprintf \"%s/%s_chirps_and_melodies.mat\" SAVE_DIR DATASET_NAME)\n",
    "saved_mat_data_stage3 = matreadsorted(filename_stage3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef01b19-5f5b-4475-abce-fdb0ae0e21ca",
   "metadata": {},
   "source": [
    "### Breakdown of saved data\n",
    "\n",
    "**`valid_mics`**: exactly the same as in Stage 2.\n",
    "\n",
    "**`highest_snr_estimated_chirp_per_chirp_seq`**: matrix where each column corresponds to a different bat vocalization. Each column contains the highest-SNR estimate of the bat vocalization for the corresponding multi-mic chirp sequence.\n",
    "\n",
    "**`highest_snr_chirp_length_per_chirp_seq`**: length, in samples, of the chirps in `highest_snr_estimated_chirp_per_chirp_seq`.\n",
    "\n",
    "**`highest_snr_melody_kHz_per_chirp_seq`**: matrix where each column corresponds to a different bat vocalization. Each column is the fundamental harmonic, in kHz, estimated using the corresponding column of `highest_snr_estimated_chirp_per_chirp_seq`.\n",
    "\n",
    "**`updated_vocalization_times`**: now, we have a (hopefully) better estimate of when each bat vocalization happened.\n",
    "\n",
    "**Rest of the variables:**\n",
    "\n",
    "- `mic_k_chirp_lengths`: length, in samples, of the vocalization estimated by mic `k` for each multi-mic chirp sequence. This (and all subsequent variables lister here) will be `0` for vocalizations that mic `k` did not pick up.\n",
    "- `mic_k_estimated_chirp_per_chirp_seq`: matrix where each column corresponds to a different bat vocalization. Each column contains the vocalization that mic `k` estimated for the corresponding multi-mic chirp sequence. \n",
    "- `mic_k_melody_kHz_per_chirp_seq`: matrix where each column corresponds to a different bat vocalization.  Each column is the fundamental harmonic, in kilohertz, estimated by mic `k`, of the bat vocalization. This will be the same length as `mic_k_estimated_chirp_per_chirp_seq`.\n",
    "- `mic_k_samples_cut_off_from_beginning_per_chirp_seq`: The number of samples, if, any, were cut off from the beginning of the corresponding estimated chirp due to low SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3477b3a0-f32b-4fd6-b6c7-c3db2047ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_vocalization_times = saved_mat_data_stage3[\"updated_vocalization_times\"];\n",
    "println(\"There were \", length(updated_vocalization_times), \" vocalizations!\");\n",
    "# myplot(updated_vocalization_times, ones(length(updated_vocalization_times)), line=:stem, marker=:circle, color=:1, markersize=5,\n",
    "#     title=\"Vocalizations \", xlabel=\"Milliseconds\", ylabel=\"\", size=(1200, 200), yrange=(0, 1.2), legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c01c500-a4a4-43d6-b1a8-978bc91a6875",
   "metadata": {},
   "source": [
    "**Get the estimated chirp and melody for a vocalization, using the highest-SNR data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3297d-65ad-4065-8d64-5e12381617a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHIRP_NUM = 8; # You can change this to look at another vocalization\n",
    "len = saved_mat_data_stage3[\"highest_snr_chirp_length_per_chirp_seq\"][CHIRP_NUM];\n",
    "estimated_chirp = saved_mat_data_stage3[\"highest_snr_estimated_chirp_per_chirp_seq\"][1:len, CHIRP_NUM];\n",
    "estimated_melody_kHz = saved_mat_data_stage3[\"highest_snr_melody_kHz_per_chirp_seq\"][1:len, CHIRP_NUM];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a74dd8-852b-43e4-82a2-bcf1a3e13b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSTFTtime(estimated_chirp, noverlap=255);\n",
    "plot!(audioindextoms.((1:len) .+ 128), estimated_melody_kHz, linewidth=3, color=:blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d190a-dd43-4e82-9bc0-44d9a2d7e87c",
   "metadata": {},
   "source": [
    "### Stage 4: Optimized Chirps\n",
    "\n",
    "**Note** this section is not for the impatient; it takes a long time to run the `saveoptimizationresults` cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b358634-8a0a-456a-b2ca-e5fc5b680871",
   "metadata": {},
   "source": [
    "### Parameters (From `Walkthrough.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238d8df-1bd7-4d02-8bd2-046791e340d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET THESE PARAMETERS ###\n",
    "H_FFT_THRESH = 0.1;\n",
    "DATA_FITTING_WEIGHT = 70;\n",
    "H_SPARSITY_WEIGHT = 10;\n",
    "MELODY_WEIGHT = 35;\n",
    "MAX_ITER = 10000;\n",
    "MELODY_RADIUS_START = 10;\n",
    "MELODY_RADIUS_END = 0;\n",
    "#############################\n",
    "OPT_PARAMS = Dict(\n",
    "    :h_fft_thresh => H_FFT_THRESH,\n",
    "    :data_fitting_weight => DATA_FITTING_WEIGHT,\n",
    "    :h_sparsity_weight => H_SPARSITY_WEIGHT,\n",
    "    :melody_weight => MELODY_WEIGHT,\n",
    "    :max_iter => MAX_ITER,\n",
    "    :melody_radius_start => MELODY_RADIUS_START,\n",
    "    :melody_radius_end => MELODY_RADIUS_END,\n",
    "    CHIRP_MELODY_PARAMS...\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc72b23-c365-4235-b2ab-412b328b523a",
   "metadata": {},
   "source": [
    "### Load Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1736f0c-bd35-4ce4-820e-fbc3caf681bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"SaveOptimizationResult.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e56852-3219-45fe-9d8f-60fd5970b7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saveoptimizationresult(y, centroids, mic_positions, DATASET_NAME, SAVE_DIR; OPT_PARAMS...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8902930-3493-444a-85bf-c69cdb549a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_stage4 = (@sprintf \"%s/%s_optimization_result.mat\" SAVE_DIR DATASET_NAME)\n",
    "saved_mat_data_stage4 = matreadsorted(filename_stage4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a3c9f-5ae9-4c81-b933-261ab0bd4b16",
   "metadata": {},
   "source": [
    "### Breakdown of saved data\n",
    "\n",
    "**`valid_mics`**: exactly the same as in Stage 2.\n",
    "\n",
    "**`estimated_vocalizations`**: matrix where each column corresponds to a different bat vocalization. Each column is what the optimization algorithm estimates the bat vocalization to be.\n",
    "\n",
    "**`estimated_vocalization_lengths`**: the estimated length, in microphone samples, of each bat vocalization.\n",
    "\n",
    "**`mic_k_impulse_response_per_chirp_seq`**: matrix where each column corresponds to a different bat vocalization. Each column is the impulse response that maps the estimated vocalization to the corresponding microphone output. This is all zero if the microphone didn't pick up the vocalization.\n",
    "\n",
    "**`impulse_response_lengths`**: the length of the impulse responses for each vocalization. The impulse response for each microphone has the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d7188f-67e9-4f74-81b3-f29c65172358",
   "metadata": {},
   "source": [
    "**Get the estimated chirp for a vocalization**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6961f81-8453-49a6-a469-05dc75dd607d",
   "metadata": {},
   "source": [
    "_Run the following cell once_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3218036-afaa-43a5-8c03-102b3fa25dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92bb56-ae64-466e-b207-24f6f49e2aa5",
   "metadata": {},
   "source": [
    "_Then run this cell again and again to loop through the vocalizations:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292563ef-d79d-4f84-8d99-2539221943b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = min(i+1, length(saved_mat_data_stage4[\"estimated_vocalization_lengths\"]));\n",
    "(@printf \"Vocalization %d\\n\" i);\n",
    "if i == length(saved_mat_data_stage4[\"estimated_vocalization_lengths\"])\n",
    "    println(\"(this is the last vocalization)\");\n",
    "end\n",
    "\n",
    "CHIRP_NUM = i; # You can change this to look at another vocalization\n",
    "len = saved_mat_data_stage4[\"estimated_vocalization_lengths\"][CHIRP_NUM];\n",
    "estimated_chirp = saved_mat_data_stage4[\"estimated_vocalizations\"][1:len, CHIRP_NUM];\n",
    "plotSTFTtime(estimated_chirp, noverlap=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355866e3-082e-4880-8b9b-7f9a9d3ed1da",
   "metadata": {},
   "source": [
    "**Compare with Highest-SNR Mic Output**\n",
    "\n",
    "The top plot is the output of the optimization algorithm (should be de-echoed), and the bottom plot is what the highest-SNR microphone picked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf95134c-7f76-47e7-83d0-51d8609a6822",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec5234-7974-47f6-a0cd-f4fc6f1f9f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = min(i+1, length(saved_mat_data_stage4[\"estimated_vocalization_lengths\"]));\n",
    "(@printf \"Vocalization %d\\n\" i);\n",
    "if i == length(saved_mat_data_stage4[\"estimated_vocalization_lengths\"])\n",
    "    println(\"(this is the last vocalization)\");\n",
    "end\n",
    "\n",
    "CHIRP_NUM = i; # You can change this to look at another vocalization\n",
    "len = saved_mat_data_stage4[\"estimated_vocalization_lengths\"][CHIRP_NUM];\n",
    "estimated_chirp = saved_mat_data_stage4[\"estimated_vocalizations\"][1:len, CHIRP_NUM];\n",
    "chirp_init = saved_mat_data_stage3[\"highest_snr_estimated_chirp_per_chirp_seq\"][1:len, CHIRP_NUM];\n",
    "p1 = plotSTFTtime(estimated_chirp, noverlap=255, title=\"Optimized Vocalization Estimate\");\n",
    "p2 = plotSTFTtime(chirp_init, noverlap=255, title=\"Highest-SNR Mic Output\");\n",
    "plot(p1, p2, layout=(2, 1), size=(1100, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48deb8-df27-43ef-b3f4-ee18977d0c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
